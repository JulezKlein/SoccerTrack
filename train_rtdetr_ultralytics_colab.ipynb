{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kex92r41khju",
   "metadata": {
    "id": "Kex92r41khju"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Clone the SoccerTrack repository\n",
    "if not os.path.isdir(\"/content/SoccerTrack\"):\n",
    "    print(\"Cloning SoccerTrack repository...\")\n",
    "    os.system(\"git clone https://github.com/JulezKlein/SoccerTrack.git /content/SoccerTrack\")\n",
    "    print(\"‚úì Repository cloned\")\n",
    "else:\n",
    "    print(\"‚úì SoccerTrack repository already exists\")\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(\"/content/SoccerTrack\")\n",
    "sys.path.insert(0, \"/content/SoccerTrack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gTSwg90roen3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTSwg90roen3",
    "outputId": "9cab536e-ef9f-4626-c70a-2e2bac8b2e83"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET = \"football\"  # Change to \"soccertrack\" if using that dataset\n",
    "VIEW_TYPE = \"top_view\"  # Only relevant for soccertrack (\"top_view\" or \"wide_view\")\n",
    "MODEL = \"rtdetr-l\"  # Options: yolov8s, yolov8n, yolo26n, rtdetr-l, rtdetr-x\n",
    "EPOCHS = 70\n",
    "IMG_SIZE = 640\n",
    "\n",
    "# Mount Google Drive (for Colab data access)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úì Google Drive mounted\")\n",
    "    DATA_DIR = \"/content/drive/MyDrive/datasets\"\n",
    "except:\n",
    "    print(\"‚ö† Google Colab not detected - running in local environment\")\n",
    "    DATA_DIR = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "initial_id",
    "outputId": "b3ad0854-5b10-45d2-a2c5-7eb5a7e90a72"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Environment Setup\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Device available: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA available: True\")\n",
    "    os.system(\"nvidia-smi\")\n",
    "else:\n",
    "    print(\"CUDA available: False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6j4b4RHh6RHS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6j4b4RHh6RHS",
    "outputId": "98f854cd-643d-4d2f-8774-64f86317ee58"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Installing Dependencies\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\", \"-q\"], check=True)\n",
    "subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \n",
    "     \"ultralytics\", \"pandas\", \"pillow\", \"tqdm\", \"opencv-python\", \"matplotlib\", \"-q\"],\n",
    "    check=True\n",
    ")\n",
    "print(\"‚úì Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hVVoZ_MjUlRr",
   "metadata": {
    "id": "hVVoZ_MjUlRr"
   },
   "outputs": [],
   "source": [
    "# Import training functions from the script\n",
    "from train_ultralytics_models import (\n",
    "    configure_dataset,\n",
    "    unzip_dataset,\n",
    "    prepare_dataset,\n",
    "    validate_dataset,\n",
    "    visualize_sample,\n",
    "    start_training\n",
    ")\n",
    "\n",
    "# Configure dataset\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Configuring Dataset: {DATASET.upper()}\")\n",
    "print(\"=\"*60)\n",
    "config = configure_dataset(dataset_type=DATASET, view_type=VIEW_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O786F3h_YrL6",
   "metadata": {
    "id": "O786F3h_YrL6"
   },
   "outputs": [],
   "source": [
    "# Prepare dataset (only if needed for SoccerTrack)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Dataset Preparation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if config[\"requires_preparation\"]:\n",
    "    print(f\"Preparing {DATASET} dataset for training...\")\n",
    "    unzip_dataset()\n",
    "    prepare_dataset()\n",
    "    print(\"‚úì Dataset preparation complete\")\n",
    "else:\n",
    "    print(f\"‚úì {DATASET} dataset is already in expected format\")\n",
    "    print(\"  No preparation needed - data should be uploaded to:\")\n",
    "    print(f\"  {config['dataset_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ABZVOb4DolX-",
   "metadata": {
    "id": "ABZVOb4DolX-"
   },
   "outputs": [],
   "source": [
    "# Visualize sample from dataset\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Visualizing Sample\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    visualize_sample()\n",
    "    print(\"‚úì Sample visualization complete\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Could not visualize sample: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KPSXNz0JxsS1",
   "metadata": {
    "id": "KPSXNz0JxsS1"
   },
   "outputs": [],
   "source": [
    "# Validate dataset before training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Validating Dataset Format\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    validate_dataset()\n",
    "    print(\"‚úì Dataset validation successful\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Validation warning: {e}\")\n",
    "    print(\"  Proceeding with training anyway...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S_Wh1eyANtMA",
   "metadata": {
    "id": "S_Wh1eyANtMA"
   },
   "outputs": [],
   "source": [
    "# Print training configuration\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: {DATASET}\")\n",
    "if DATASET == \"soccertrack\":\n",
    "    print(f\"View Type: {VIEW_TYPE}\")\n",
    "print(f\"Model: {MODEL}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Image Size: {IMG_SIZE}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Output Dir: {config['output_dir']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RL-QltfbbJpL",
   "metadata": {
    "id": "RL-QltfbbJpL"
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Starting {MODEL.upper()} Training\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    results = start_training(\n",
    "        epochs=EPOCHS,\n",
    "        img_size=IMG_SIZE,\n",
    "        model_name=MODEL\n",
    "    )\n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "    print(f\"Results saved to: {config['output_dir']}/{MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PGkTDtrdywL2",
   "metadata": {
    "id": "PGkTDtrdywL2"
   },
   "outputs": [],
   "source": [
    "# Optional: Check training results\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(config['output_dir']) / MODEL\n",
    "if output_dir.exists():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Training Results\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # List results directories\n",
    "    result_dirs = list(output_dir.glob(\"train*\"))\n",
    "    if result_dirs:\n",
    "        latest_run = max(result_dirs, key=lambda p: p.stat().st_mtime)\n",
    "        print(f\"Latest training run: {latest_run.name}\")\n",
    "        \n",
    "        # List key files\n",
    "        weights_dir = latest_run / \"weights\"\n",
    "        if weights_dir.exists():\n",
    "            print(f\"\\nWeights:\")\n",
    "            for weight_file in weights_dir.glob(\"*.pt\"):\n",
    "                print(f\"  - {weight_file.name}\")\n",
    "        \n",
    "        # Check for results.csv\n",
    "        results_csv = latest_run / \"results.csv\"\n",
    "        if results_csv.exists():\n",
    "            print(f\"\\n‚úì Results logged to: {results_csv}\")\n",
    "    else:\n",
    "        print(\"No completed training runs found yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V6BIyJhv8pes",
   "metadata": {
    "id": "V6BIyJhv8pes"
   },
   "outputs": [],
   "source": [
    "# Optional: Download trained model from Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    weights_path = output_dir / \"train\" / \"weights\" / \"best.pt\"\n",
    "    if weights_path.exists():\n",
    "        print(f\"\\nDownloading trained model: {weights_path.name}\")\n",
    "        files.download(str(weights_path))\n",
    "        print(\"‚úì Model download started\")\n",
    "    else:\n",
    "        print(\"No trained weights found to download\")\n",
    "except ImportError:\n",
    "    print(\"(Google Colab environment not detected - skipping download)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXPORT CONFIGURATION\n",
    "# ============================================================\n",
    "# Choose export format(s): \"coreml\", \"onnx\", or \"both\"\n",
    "EXPORT_FORMAT = \"coreml\"  # Change to \"onnx\" or \"both\" as needed\n",
    "EXPORT_FP16 = True  # Use FP16 precision (False for FP32)\n",
    "DISABLE_NMS = False  # Set True to disable NMS in exported model\n",
    "\n",
    "CONF_THRESH = 0.4  # Confidence threshold baked into model\n",
    "IOU_THRESH = 0.2   # IoU threshold baked into model\n",
    "\n",
    "# Find the best weights from training\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "output_path = Path(config['output_dir']) / MODEL\n",
    "result_dirs = sorted(output_path.glob(\"train*\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if result_dirs:\n",
    "    WEIGHTS = str(result_dirs[0] / \"weights\" / \"best.pt\")\n",
    "    print(f\"Found trained weights: {WEIGHTS}\")\n",
    "else:\n",
    "    WEIGHTS = f\"runs/detect/output_yolo_football/{MODEL}/weights/best.pt\"\n",
    "    print(f\"Using default weights path: {WEIGHTS}\")\n",
    "    \n",
    "print(f\"\\nExport Configuration:\")\n",
    "print(f\"  Format: {EXPORT_FORMAT}\")\n",
    "print(f\"  FP16: {EXPORT_FP16}\")\n",
    "print(f\"  NMS: {not DISABLE_NMS}\")\n",
    "print(f\"  Conf Threshold: {CONF_THRESH}\")\n",
    "print(f\"  IoU Threshold: {IOU_THRESH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXPORT FUNCTIONS\n",
    "# ============================================================\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def export_coreml():\n",
    "    \"\"\"Export model to Core ML format\"\"\"\n",
    "    print(\"üîÑ Loading YOLO model...\")\n",
    "    model = YOLO(WEIGHTS)\n",
    "\n",
    "    print(\"üì¶ Exporting to Core ML...\")\n",
    "    try:\n",
    "        model.export(\n",
    "            format=\"coreml\",\n",
    "            imgsz=IMG_SIZE,\n",
    "            nms=not DISABLE_NMS,\n",
    "            half=EXPORT_FP16,\n",
    "            conf=CONF_THRESH,\n",
    "            iou=IOU_THRESH,\n",
    "            data=config['yaml_path']\n",
    "        )\n",
    "        print(\"‚úÖ Core ML export finished\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Core ML export failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def export_onnx():\n",
    "    \"\"\"Export model to ONNX format\"\"\"\n",
    "    print(\"üîÑ Loading YOLO model...\")\n",
    "    model = YOLO(WEIGHTS)\n",
    "\n",
    "    print(\"üì¶ Exporting to ONNX...\")\n",
    "    try:\n",
    "        model.export(\n",
    "            format=\"onnx\",\n",
    "            imgsz=IMG_SIZE,\n",
    "            nms=not DISABLE_NMS,\n",
    "            end2end=True,\n",
    "            conf=CONF_THRESH,\n",
    "            iou=IOU_THRESH,\n",
    "            half=EXPORT_FP16,\n",
    "            data=config['yaml_path']\n",
    "        )\n",
    "        print(\"‚úÖ ONNX export finished\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ONNX export failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def quick_test_coreml():\n",
    "    \"\"\"Test Core ML model with dummy input\"\"\"\n",
    "    print(\"\\nüß™ Running Core ML inference test...\")\n",
    "    \n",
    "    try:\n",
    "        import coremltools as ct\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è coremltools not installed. Installing...\")\n",
    "        os.system(\"pip install coremltools -q\")\n",
    "        import coremltools as ct\n",
    "\n",
    "    mlpackage_path = WEIGHTS.replace(\".pt\", \".mlpackage\")\n",
    "\n",
    "    if not os.path.exists(mlpackage_path):\n",
    "        print(f\"‚ö†Ô∏è Core ML model not found at {mlpackage_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        mlmodel = ct.models.MLModel(mlpackage_path)\n",
    "        print(\"‚úì Core ML model loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load Core ML model: {e}\")\n",
    "        return\n",
    "\n",
    "    dummy_input = Image.new(mode=\"RGB\", size=(IMG_SIZE, IMG_SIZE), color=(128, 128, 128))\n",
    "\n",
    "    try:\n",
    "        outputs = mlmodel.predict({\"image\": dummy_input})\n",
    "        print(\"‚úÖ Core ML inference successful\")\n",
    "        print(\"üì§ Output keys:\")\n",
    "        for k, v in outputs.items():\n",
    "            try:\n",
    "                print(f\"  - {k}: {v.shape}\")\n",
    "            except:\n",
    "                print(f\"  - {k}: (non-array output)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Core ML inference failed: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        t0 = time.perf_counter()\n",
    "        _ = mlmodel.predict({\"image\": dummy_input})\n",
    "        t1 = time.perf_counter()\n",
    "        elapsed_ms = (t1 - t0) * 1000.0\n",
    "        print(f\"‚è±Ô∏è Core ML inference time: {elapsed_ms:.2f} ms\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Core ML timing failed: {e}\")\n",
    "\n",
    "\n",
    "def quick_test_onnx():\n",
    "    \"\"\"Test ONNX model with dummy input\"\"\"\n",
    "    print(\"\\nüß™ Running ONNX runtime inference test...\")\n",
    "\n",
    "    try:\n",
    "        import onnxruntime as ort\n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è onnxruntime not installed. Installing...\")\n",
    "        os.system(\"pip install onnxruntime -q\")\n",
    "        import onnxruntime as ort\n",
    "\n",
    "    onnx_path = WEIGHTS.replace(\".pt\", \".onnx\")\n",
    "    \n",
    "    if not os.path.exists(onnx_path):\n",
    "        print(f\"‚ö†Ô∏è ONNX model not found at {onnx_path}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        sess = ort.InferenceSession(onnx_path)\n",
    "        print(\"‚úì ONNX model loaded successfully\")\n",
    "        \n",
    "        input_name = sess.get_inputs()[0].name\n",
    "        dummy = np.random.rand(1, 3, IMG_SIZE, IMG_SIZE).astype(np.float32)\n",
    "        \n",
    "        # Warm-up\n",
    "        sess.run(None, {input_name: dummy})\n",
    "        \n",
    "        # Timed run\n",
    "        t0 = time.perf_counter()\n",
    "        outputs = sess.run(None, {input_name: dummy})\n",
    "        t1 = time.perf_counter()\n",
    "        elapsed_ms = (t1 - t0) * 1000.0\n",
    "        \n",
    "        print(\"‚úÖ ONNX runtime inference successful\")\n",
    "        print(f\"‚è±Ô∏è ONNX inference time: {elapsed_ms:.2f} ms\")\n",
    "        print(\"üì§ Output tensors:\")\n",
    "        for i, out in enumerate(outputs):\n",
    "            print(f\"  - output[{i}]: shape={getattr(out, 'shape', 'unknown')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ONNX runtime test failed: {e}\")\n",
    "\n",
    "\n",
    "print(\"‚úì Export functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f919d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RUN EXPORTS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Export\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fmt = EXPORT_FORMAT.strip().lower() if isinstance(EXPORT_FORMAT, str) else \"coreml\"\n",
    "\n",
    "if fmt == \"coreml\":\n",
    "    if export_coreml():\n",
    "        quick_test_coreml()\n",
    "elif fmt == \"onnx\":\n",
    "    if export_onnx():\n",
    "        quick_test_onnx()\n",
    "elif fmt == \"both\":\n",
    "    print(\"\\nüì¶ Exporting to both formats...\\n\")\n",
    "    if export_coreml():\n",
    "        quick_test_coreml()\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "    if export_onnx():\n",
    "        quick_test_onnx()\n",
    "else:\n",
    "    print(f\"‚ùå Unsupported EXPORT_FORMAT: {EXPORT_FORMAT}\")\n",
    "    print(\"   Choose 'coreml', 'onnx', or 'both'\")\n",
    "\n",
    "print(\"\\n‚úÖ Export pipeline complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d54430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DOWNLOAD EXPORTED MODELS (Colab only)\n",
    "# ============================================================\n",
    "try:\n",
    "    from google.colab import files\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Downloading Exported Models\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    files_to_download = []\n",
    "    \n",
    "    if fmt in [\"coreml\", \"both\"]:\n",
    "        mlpackage_path = WEIGHTS.replace(\".pt\", \".mlpackage\")\n",
    "        if os.path.exists(mlpackage_path):\n",
    "            print(f\"üì¶ Found Core ML model: {os.path.basename(mlpackage_path)}\")\n",
    "            files_to_download.append(mlpackage_path)\n",
    "    \n",
    "    if fmt in [\"onnx\", \"both\"]:\n",
    "        onnx_path = WEIGHTS.replace(\".pt\", \".onnx\")\n",
    "        if os.path.exists(onnx_path):\n",
    "            print(f\"üì¶ Found ONNX model: {os.path.basename(onnx_path)}\")\n",
    "            files_to_download.append(onnx_path)\n",
    "    \n",
    "    # Also download the best.pt weights\n",
    "    pt_weights = WEIGHTS\n",
    "    if os.path.exists(pt_weights):\n",
    "        print(f\"üì¶ Found PyTorch weights: {os.path.basename(pt_weights)}\")\n",
    "        files_to_download.append(pt_weights)\n",
    "    \n",
    "    if files_to_download:\n",
    "        print(f\"\\nüì• Downloading {len(files_to_download)} file(s)...\")\n",
    "        for file_path in files_to_download:\n",
    "            print(f\"  ‚Üí {os.path.basename(file_path)}\")\n",
    "            files.download(file_path)\n",
    "        print(\"‚úÖ Download complete!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No exported models found to download\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Export Summary\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"‚úì Google Colab environment not detected\")\n",
    "    print(\"  (Skipping automatic download)\")\n",
    "    print(f\"\\nüìÅ Exported model location:\")\n",
    "    print(f\"  {os.path.dirname(WEIGHTS)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
